{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a665ba18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hlm/Documents/Mini-RAG/.rag/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain_core.documents import Document \n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54023e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/cleaned/IFRS_9.txt\", \"r\", encoding=\"utf-8\") as file :\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f8f574",
   "metadata": {},
   "source": [
    "Now I will create the metadata tree before chunking the datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86071d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chapter_regex = r\"\\n(Chapter [1-9] [A-Z].*)\\n\"\n",
    "Appendix_regex = r\"(Appendix [A-Z] (?=[A-Z]))\"\n",
    "Chapters_elem = re.split(f\"{Chapter_regex}|{Appendix_regex}\", text)\n",
    "\n",
    "#No intro\n",
    "if \"Chapter\" not in Chapters_elem[0] :\n",
    "    Chapters_elem = Chapters_elem[1:]\n",
    "\n",
    "whole_text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6cdc737",
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in range(0,len(Chapters_elem),3) :\n",
    "\n",
    "    if Chapters_elem[elem] :\n",
    "        true_chapter_name = Chapters_elem[elem]\n",
    "    else :\n",
    "        true_chapter_name = Chapters_elem[elem+1]\n",
    "\n",
    "    pattern_parts = r\"(?<![\\d\\.])([A-Z]?\\d\\.\\d) (?=[A-Z])\"\n",
    "    nb_parts = re.findall(pattern_parts, Chapters_elem[elem+2]) \n",
    "    \n",
    "    splitted = re.split(\" \",true_chapter_name)\n",
    "    chapter_id = splitted[1]\n",
    "    chapter_txt = \" \"+\" \".join(splitted[2:])\n",
    "\n",
    "    if nb_parts : #With a part, only appendix with def haven't any parts\n",
    "\n",
    "        current_type = \"content\"\n",
    "        \n",
    "        parts_ = re.split(pattern_parts, Chapters_elem[elem+2])\n",
    "        parts_ = parts_[1:]\n",
    "        \n",
    "        for i in range(0,len(parts_),2):\n",
    "\n",
    "            pattern_subpart = r\"([A-Z]?\\d\\.\\d\\.\\d+[A-Z]? (?=[A-Z]))\"\n",
    "            nb_subpart = re.findall(pattern_subpart, parts_[i+1])\n",
    "\n",
    "            if nb_subpart :\n",
    "            \n",
    "                subparts = re.split(pattern_subpart, parts_[i+1])\n",
    "                \n",
    "                section_id = parts_[i].strip()\n",
    "                section_txt = \" \"+subparts[0]\n",
    "                \n",
    "                subparts = subparts[1:]\n",
    "\n",
    "                for j in range(0,len(subparts),2) : #a_pattern in subparts\n",
    "\n",
    "                    # (a) parts\n",
    "                    a_pattern = r\"\\n(\\([a-hj-z]\\) )\"\n",
    "                    nb_a_part = re.findall(a_pattern, subparts[j+1])\n",
    "\n",
    "                    if nb_a_part :\n",
    "                        \n",
    "                        a_parts = re.split(a_pattern, subparts[j+1])#[1:] #i serves as an indication for smaller part\n",
    "                        \n",
    "                        subparts_id = subparts[j].strip()\n",
    "                        subparts_txt = \" \"+a_parts[0]\n",
    "\n",
    "                        a_parts = a_parts[1:]\n",
    "\n",
    "                        for x in range(0,len(a_parts),2) :\n",
    "                            item_nb = a_parts[x].strip()\n",
    "                            item_text = \" \"+a_parts[x+1]\n",
    "\n",
    "                            final_text = true_chapter_name+\"\\n\"+section_id+section_txt+'\\n'+subparts_id+subparts_txt+'\\n'+item_nb+item_text\n",
    "                            whole_text.append({\"text\" : final_text,\n",
    "                                         \"metadata\" : {\n",
    "                                             \"chapter\" : chapter_id,\n",
    "                                             \"chapter_title\" : chapter_txt,\n",
    "                                             \"type\" : current_type,\n",
    "                                             \"section\" : section_id,\n",
    "                                             \"sub_section\" : subparts_id,\n",
    "                                             \"a_part\" : item_nb\n",
    "                                            }})\n",
    "                    \n",
    "                    else :\n",
    "                        subparts_id = subparts[j].strip()\n",
    "                        subparts_txt = \" \"+subparts[j+1]\n",
    "                        final_text = true_chapter_name+\"\\n\"+section_id+section_text+\"\\n\"+subparts_id+subparts_txt\n",
    "                        whole_text.append({\"text\" : final_text,\n",
    "                                         \"metadata\" : {\n",
    "                                             \"chapter\" : chapter_id,\n",
    "                                             \"chapter_title\" : chapter_txt,\n",
    "                                             \"type\" : current_type,\n",
    "                                             \"section\" : section_id,\n",
    "                                             \"sub_section\" : subparts_id\n",
    "                                            }})\n",
    "                    \n",
    "            else : #Chapter with part and no subpart\n",
    "\n",
    "                a_pattern = r\"\\n(\\([a-hj-z]\\) )\"\n",
    "                nb_a_part = re.findall(a_pattern, parts_[i+1])\n",
    "                \n",
    "                if nb_a_part : #a_pattern in part\n",
    "                    a_part = re.split(a_pattern, parts_[i+1])\n",
    "\n",
    "                    section_id = parts_[i].strip()\n",
    "                    section_txt = \" \"+a_part[0]\n",
    "                    \n",
    "                    a_part = a_part[1:]\n",
    "\n",
    "                    for x in range(0,len(a_part),2) :\n",
    "                        item_id = a_part[x].strip()\n",
    "                        item_text = \" \"+a_part[x+1]\n",
    "                        \n",
    "                        final_text = true_chapter_name+\"\\n\"+section_id+section_text+\"\\n\"+item_id+item_text\n",
    "                        whole_text.append({\"text\" : final_text,\n",
    "                                         \"metadata\" : {\n",
    "                                             \"chapter\" : chapter_id,\n",
    "                                             \"chapter_title\" : chapter_txt,\n",
    "                                             \"type\" : current_type,\n",
    "                                             \"section\" : section_id,\n",
    "                                             \"a_part\" : item_id\n",
    "                                            }})\n",
    "\n",
    "                else : #no a_part in the part\n",
    "                    section_id = parts_[i].strip()\n",
    "                    section_text = \" \"+parts_[i+1]\n",
    "                    \n",
    "                    final_text = true_chapter_name+\"\\n\"+section_id+section_text\n",
    "                    whole_text.append({\"text\" : final_text,\n",
    "                                         \"metadata\" : {\n",
    "                                             \"chapter\" :chapter_id,\n",
    "                                             \"chapter_title\" : chapter_txt,\n",
    "                                             \"type\" : current_type,\n",
    "                                             \"section\" : section_id\n",
    "                                            }})\n",
    "\n",
    "    else : #If no part then it's definitions\n",
    "        defs = re.split(r\"(\\w+_\\w+) |(\\n)(?=[A-Z]\\w+)\", Chapters_elem[elem+2])[1:]\n",
    "        for i in range(0,len(defs),3) :\n",
    "            if defs[i] :\n",
    "                current_type = \"definition\"\n",
    "                definition_term = defs[i].replace(\"_\",\" \")\n",
    "                \n",
    "                whole_text.append({\"text\" : true_chapter_name+'\\n'+defs[i+2],\n",
    "                                         \"metadata\" : {\n",
    "                                             \"chapter\" :chapter_id,\n",
    "                                             \"chapter_title\" : chapter_txt,\n",
    "                                             \"type\" : current_type,\n",
    "                                             \"def_term\" : definition_term\n",
    "                                            }})\n",
    "            else :\n",
    "                current_type = \"content\"\n",
    "                whole_text.append({\"text\" : true_chapter_name+'\\n'+defs[i+2],\n",
    "                                         \"metadata\" : {\n",
    "                                             \"chapter\" :chapter_id,\n",
    "                                             \"chapter_title\" : chapter_txt,\n",
    "                                             \"type\" : current_type,\n",
    "                                             }})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b621feb3",
   "metadata": {},
   "source": [
    "Chunk the datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "682c878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \"; \", \" \"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d76697bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_text = []\n",
    "\n",
    "for entry in whole_text:\n",
    "    text = entry[\"text\"]\n",
    "    metadata = entry[\"metadata\"]\n",
    "\n",
    "    chunks = splitter.split_text(text)\n",
    "\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        chunked_text.append({\n",
    "            \"text\": chunk,\n",
    "            \"metadata\": {\n",
    "                **metadata,\n",
    "                \"chunk_id\": idx \n",
    "            }\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a9be54",
   "metadata": {},
   "source": [
    "Now we can stock it in langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5103ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    Document(\n",
    "        page_content=item[\"text\"],\n",
    "        metadata=item[\"metadata\"]\n",
    "    )\n",
    "    for item in chunked_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c40a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67e54358",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(docs,hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a335118",
   "metadata": {},
   "outputs": [],
   "source": [
    "FAISS.load_local()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703eeb71",
   "metadata": {},
   "source": [
    "Store the vector base locally "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6280a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.save_local(\"faiss_ifrs_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc9249b",
   "metadata": {},
   "source": [
    "Test of the vector base with simple method (similarity search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db7f28e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "{'chapter': '6', 'chapter_title': ' Hedge accounting', 'type': 'content', 'section': '6.9', 'sub_section': '6.9.6', 'chunk_id': 1}\n",
      "Accounting for qualifying hedging relationships Cash flow hedges\n",
      "---\n",
      "{'chapter': '6', 'chapter_title': ' Hedge accounting', 'type': 'content', 'section': '6.5', 'sub_section': '6.5.10', 'chunk_id': 3}\n",
      "Cash flow hedges\n",
      "---\n",
      "{'chapter': '6', 'chapter_title': ' Hedge accounting', 'type': 'content', 'section': '6.1', 'sub_section': '6.1.1', 'chunk_id': 1}\n",
      "6.1.1 The objective of hedge accounting is to represent, in the financial statements, the effect of an entity’s risk management activities that use financial instruments to manage exposures arising from particular risks that could affect profit or loss (or other comprehensive income, in the case of investments in equity instruments for which an entity has elected to present changes in fair value in other comprehensive income in accordance with paragraph 5.7.5). This approach aims to convey the context of hedging instruments for which hedge accounting is applied in order to allow insight into their purpose and effect.\n",
      "---\n",
      "{'chapter': '6', 'chapter_title': ' Hedge accounting', 'type': 'content', 'section': '6.9', 'sub_section': '6.9.6', 'chunk_id': 0}\n",
      "Chapter 6 Hedge accounting\n",
      "6.9 A written option to buy or sell a non-financial item that can be settled net in cash or another financial instrument, or by exchanging financial instruments, in accordance with paragraph 2.6(a) or 2.6(d) is within the scope of this Standard. Such a contract cannot be entered into for the purpose of the receipt or delivery of the non-financial item in accordance with the entity’s expected purchase, sale or usage requirements.\n",
      "6.9.6 Paragraphs 6.9.7–6.9.13 provide exceptions to the requirements specified in those paragraphs only. An entity shall apply all other hedge accounting requirements in this Standard, including the qualifying criteria in paragraph 6.4.1, to hedging relationships that were directly affected by interest rate benchmark reform.\n",
      "---\n",
      "{'chapter': '6', 'chapter_title': ' Hedge accounting', 'type': 'content', 'section': '6.5', 'sub_section': '6.5.7', 'a_part': '(b)', 'chunk_id': 0}\n",
      "Chapter 6 Hedge accounting\n",
      "6.5 Accounting for qualifying hedging relationships \n",
      "6.5.7 An entity shall apply:\n",
      "(b) paragraph 6.5.12 when it discontinues hedge accounting for cash flow hedges.\n",
      "Fair value hedges\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the rules around hedge accounting ?\"\n",
    "docs = vectorstore.similarity_search(query, k=5)\n",
    "\n",
    "for d in docs:\n",
    "    print(\"---\")\n",
    "    print(d.metadata)\n",
    "    print(d.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
